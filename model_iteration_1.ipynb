{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotten Tomatoes Model Iteration 1\n",
    "#### Patrick Huston and James Jang\n",
    "\n",
    "This notebook aims to make a first pass at producing a model capable of predicting sentiment on given phrases taken from movie reviews on Rotten Tomatoes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, imports! We'll be attempting to tackle this problem from a wide array of angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bumho/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.tsv\", sep= '\\t')\n",
    "test = pd.read_csv(\"data/test.tsv\", sep= '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1\n",
    "\n",
    "As a very basic first pass, we'll try and create a model using the features we built in our data exploration notebook. While some of these features did seem to have positive correlations with the data, we don't have high hopes for the performance of this model - this mainly serves as a point of reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by dropping in the helper functions we created in the data exploration to facilitate the creation of our new features. These new features are:\n",
    "\n",
    "1. The number of words in a given phrase -- We noticed a strong correlation between the number of words and the standard deviation of the sentiment. While this wouldn't help us classify long phrases, it gives a pretty good indication that short phrases will most likely be of sentiment score 2. \n",
    "\n",
    "2. The length of the phrase in total -- This will be included for the same reason that the number of words is being used. Including both probably won't do much, but hey, let's try it anyway and see what happens.\n",
    "\n",
    "3. The average word length in a given phrase -- In our exploration, we came across some strange trends in the data relating to the average word length and its effect on the sentiment of a given phrase. We're not sure what predictive power this feature will end up having, but we'll give it a try nonetheless.\n",
    "\n",
    "4. Whether the phrase contains one or more of the most positvely correlated words in the corpus -- Pretty self-explanatory. This seems like it could help, but there are also negations and other patterns of language that could diminish this feature's predictive power.\n",
    "\n",
    "5. Whether the phrase contains one or more of the most negatively correlated words in the corpus -- same reasoning as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_phrase(phrase):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", phrase)\n",
    "    lower_case = letters_only.lower()\n",
    "    \n",
    "    words = lower_case.split()\n",
    "    stops = set(stopwords.words(\"english\")) \n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return(\" \".join( meaningful_words))   \n",
    "\n",
    "def num_words(phrase):\n",
    "    return len(phrase.split())\n",
    "\n",
    "def length_phrase(phrase):\n",
    "    return len(phrase)\n",
    "\n",
    "def avg_word_length(phrase):\n",
    "    if(phrase != ''):\n",
    "        return sum(map(len, phrase.split()))/len(phrase.split())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "most_positive = ['remarkable', 'brilliant', 'terrific', 'excellent', 'finest', 'extraordinary', 'masterful', \n",
    "                 'hilarious', 'beautiful', 'wonderful', 'breathtaking', 'powerful', 'wonderfully', 'delightful', \n",
    "                 'masterfully', 'fantastic', 'dazzling', 'funniest', 'interference', 'refreshing']\n",
    "most_negative = ['worst', 'failure', 'lacks', 'waste', 'bore', 'depressing', 'lacking', 'stupid', 'disappointment', \n",
    "                 'unfunny', 'lame', 'devoid', 'trash', 'lousy', 'junk', 'poorly', 'mess', 'sleep', 'unappealing', 'fails']\n",
    "\n",
    "def contains_positive(phrase):\n",
    "    for word in phrase.split():\n",
    "        if word in most_positive:\n",
    "            return 1 \n",
    "    return 0\n",
    "        \n",
    "def contains_negative(phrase):\n",
    "    for word in phrase.split():\n",
    "        if word in most_negative:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For even further convenience, we've wrapped the functionality of our feature creation functions into one helper function that does everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_transform(data):\n",
    "    data['CleanPhrase'] = data['Phrase'].apply(clean_phrase)\n",
    "    data['NumWords'] = data['CleanPhrase'].apply(num_words)\n",
    "    data['LengthPhrase'] = data['CleanPhrase'].apply(length_phrase)\n",
    "    data['AvgWordLength'] = data['CleanPhrase'].apply(avg_word_length)\n",
    "    data['ContainPositive'] = data['CleanPhrase'].apply(contains_positive)\n",
    "    data['ContainNegative'] = data['CleanPhrase'].apply(contains_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our transformation functions to the training and testing datasets now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apply_transform(train)\n",
    "apply_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned and features have been created, let's try running some models on the dataset. We'll try a couple of different options - first a logistic regression, and then perhaps a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression mean score: 0.525015974421\n",
      "Random forest mean score: 0.519191245532\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"ContainPositive\", \"ContainNegative\", \"NumWords\", \"LengthPhrase\", \"AvgWordLength\"]\n",
    "logisticReg = LogisticRegression(random_state=1)\n",
    "randomForest = RandomForestClassifier(random_state=1, n_estimators=1000, min_samples_split=8, min_samples_leaf=4)\n",
    "mean_score_logistic = cross_validation.cross_val_score(logisticReg, train[predictors], train[\"Sentiment\"], cv=3).mean()\n",
    "mean_score_forest = cross_validation.cross_val_score(randomForest, train[predictors], train[\"Sentiment\"], cv=3).mean()\n",
    "\n",
    "print \"Logistic regression mean score: {}\".format(mean_score_logistic)\n",
    "print \"Random forest mean score: {}\".format(mean_score_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around the 50% mark isn't far from where we expected such a simple model would fall. Clearly our heroic efforts at initial attempts of creating numerical features from text data haven't gotten us very far. We're going to need to call in a bigger, badder, model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Enter bag of words/tfidf/count vectorizer! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by doing some research on how scikit-learn can deal with text data, and after some poking around, we stumbled up on a [Tutorial](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) that goes over the process of combining the powers of [tfidf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) and a supervised learning model, like some of the models mentionted in the scikit-learn [Multiclass and Multilabel](http://scikit-learn.org/stable/modules/multiclass.html) docs. \n",
    "\n",
    "As suggested by the scikit-learn docs mentioned above, we started with a MultinomailNB naive Bayes model --\n",
    "\n",
    "```\n",
    "Let’s start with a naïve Bayes classifier, which provides a nice baseline for this task. scikit-learn includes several variants of this classifier; the one most suitable for word counts is the multinomial variant.\n",
    "```\n",
    "\n",
    "Additionally, we implemented this all using the awesome scikit-learn Pipeline class that behaves like a compound classifier. \n",
    "\n",
    "Essentially what it does is this ~ vectorizer => transformer => classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipelineBayes = Pipeline([('vect', CountVectorizer()),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also created another pipeline at the same time to try out a different training model - the [OneVsOneClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier) strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelineOneVOne = Pipeline([('vect', CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 5000)),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', OneVsOneClassifier(LinearSVC())),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our pipelines constructed, let's get some idea to see if all of our work has paid off - some simple scikit-learn cross validation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score for Bayes model: 0.553844611375\n",
      "Mean score for OnevOne Model: 0.592489915764\n"
     ]
    }
   ],
   "source": [
    "predictors = \"Phrase\"\n",
    "\n",
    "bayes_mean = cross_validation.cross_val_score(pipelineBayes, train[predictors], train[\"Sentiment\"], cv=3).mean()\n",
    "onevone_mean = cross_validation.cross_val_score(pipelineOneVOne, train[predictors], train[\"Sentiment\"], cv=3).mean()\n",
    "\n",
    "print \"Mean score for Bayes model: {}\".format(bayes_mean)\n",
    "print \"Mean score for OnevOne Model: {}\".format(onevone_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Nearly 60% is a marked improvement over previous models, and with some additional tuning, we were able to get up to ~62% on a Kaggle submission. Speaking of Kaggle submissions, let's create some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelineBayes = pipelineBayes.fit(train.Phrase, train.Sentiment)\n",
    "pipelineOneVOne = pipelineOneVOne.fit(train.Phrase, train.Sentiment)\n",
    "\n",
    "predictionBayes = pipelineBayes.predict(test.Phrase)\n",
    "predictionOnevOne = pipelineOneVOne.predict(test.Phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When submitted to Kaggle, these submissions receive scores of around 57% and 60%. We have more work to do, but this feels like a pretty good benchmark to start from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"PhraseId\":test[\"PhraseId\"], \"Sentiment\":predictionOnevOne} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv(\"submission.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "From the bag of words Kaggle competition we found a tutorial about Google's Word2Vec and decided to implement it on our dataset [Tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSentences(data):\n",
    "    sentenceK = data['SentenceId'].drop_duplicates()\n",
    "    sentences = data.iloc[sentenceK.keys()]\n",
    "    return sentences\n",
    "\n",
    "def review_to_wordlist(review):\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    words = review_text.lower().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec requires lists of sentences so we had to group our data by sentenceId. We do not actually need a tokenizer to split the paragraphs into sentences as shown in the tutorial because our dataset is already split by sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "sentences = getSentences(train)\n",
    "\n",
    "sentencesWord2Vec = []  # Initialize an empty list of sentences\n",
    "\n",
    "print \"Parsing sentences from training set\"\n",
    "for sentence in sentences[\"Phrase\"]:\n",
    "    sentencesWord2Vec.append(review_to_wordlist(sentence))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose', 'is', 'also', 'good', 'for', 'the', 'gander', 'some', 'of', 'which', 'occasionally', 'amuses', 'but', 'none', 'of', 'which', 'amounts', 'to', 'much', 'of', 'a', 'story']\n",
      "['this', 'quiet', 'introspective', 'and', 'entertaining', 'independent', 'is', 'worth', 'seeking']\n"
     ]
    }
   ],
   "source": [
    "print sentencesWord2Vec[0]\n",
    "print sentencesWord2Vec[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked the first couple of sentences to confirm we had created the correct data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(sentencesWord2Vec, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'man'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('every', 0.999800443649292),\n",
       " ('history', 0.9997934699058533),\n",
       " ('beautiful', 0.9997863173484802),\n",
       " ('whose', 0.9997856020927429),\n",
       " ('american', 0.9997774958610535),\n",
       " ('heart', 0.9997736215591431),\n",
       " ('mr', 0.999771237373352),\n",
       " ('itself', 0.9997618198394775),\n",
       " ('style', 0.9997585415840149),\n",
       " ('place', 0.999748706817627)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('premise', 0.9996559619903564),\n",
       " ('solid', 0.99965500831604),\n",
       " ('almost', 0.9996353983879089),\n",
       " ('children', 0.9996174573898315),\n",
       " ('manages', 0.9996157884597778),\n",
       " ('men', 0.9996124505996704),\n",
       " ('piece', 0.9996122121810913),\n",
       " ('takes', 0.9996058940887451),\n",
       " ('around', 0.9996020793914795),\n",
       " ('charming', 0.9995979070663452)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('probably', 0.9996588230133057),\n",
       " ('kids', 0.9996249675750732),\n",
       " ('how', 0.9996124505996704),\n",
       " ('going', 0.9995927810668945),\n",
       " ('why', 0.999585747718811),\n",
       " ('still', 0.9995747804641724),\n",
       " ('need', 0.9995580315589905),\n",
       " ('worth', 0.9995493292808533),\n",
       " ('anyone', 0.999543309211731),\n",
       " ('again', 0.9995189905166626)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our model took a very short time and as we can see the was not very accurate at all. doesnt_match function and most_similar don't seem to be working very well. Word2Vec works better as the size of its training data grows. We were only able to provide the model around 8544 sentences which is very small. Word2Vec is also supposed to work with a lot of unlabeld text so we had to disregard the Sentiment data we had. which goes out to say that we weren't really using the best model for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Future Iterations\n",
    "\n",
    "In future iterations, we aim to explore some of the following methods more.\n",
    "\n",
    "1. Training Word2Vec on a larger dataset\n",
    "2. Implement a porter-stemmer algorithm on the data\n",
    "3. Utilize the fact that the test data does include the SentenceId - we're currently analyzing only based on the raw text, and including\n",
    "4. See if we can figure out how to include negations \n",
    "5. Look around at existing APIs - like pattern - that could help us improve our submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
